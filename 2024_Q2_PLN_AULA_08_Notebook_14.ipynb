{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adalves-ufabc/2022.Q2-PLN/blob/main/2024_Q2_PLN_AULA_08_Notebook_14.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Processamento de Linguagem Natural [2024-Q2]**\n",
        "Prof. Alexandre Donizeti Alves"
      ],
      "metadata": {
        "id": "g1W8SH-MUgZZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Introdu√ß√£o √† API da OpenAI**\n",
        "---\n"
      ],
      "metadata": {
        "id": "7Kta7e1AUeub"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sFIowMuI69Lv",
        "outputId": "04db8c11-f588-4d59-d42e-4e75c231506a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.10.12 (main, Mar 22 2024, 16:50:05) [GCC 11.4.0]\n"
          ]
        }
      ],
      "source": [
        "#@title Vers√£o do Python no Google Colab\n",
        "\n",
        "import sys\n",
        "\n",
        "print(sys.version)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kwdwRDIwC5Me"
      },
      "source": [
        "## **Configura√ß√£o da API**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjLmc6Yr1a2B",
        "outputId": "77d221ce-16dc-49b2-cb02-da26601b0478"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.37.0-py3-none-any.whl (337 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m337.0/337.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.7.4)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.37.0\n"
          ]
        }
      ],
      "source": [
        "#@title Instalando a biblioteca da API da OpenAI\n",
        "\n",
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbFq4KS1fa4T",
        "outputId": "15d17c4d-c995-40dd-9989-745403ebe47f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.37.0\n"
          ]
        }
      ],
      "source": [
        "#@title Vers√£o da API da OpenAI\n",
        "import openai\n",
        "\n",
        "print(openai.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lKCJiyiP-UaU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5912837b-f5cc-4c08-bd29-3d7ad4fcef53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"
          ]
        }
      ],
      "source": [
        "#@title Definindo a chave da API\n",
        "\n",
        "from getpass import getpass\n",
        "\n",
        "OPENAI_API_KEY = getpass()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDMK2_pJSD_q"
      },
      "source": [
        "## **Exemplos**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "baQkdS4qNBBX"
      },
      "outputs": [],
      "source": [
        "# fun√ß√£o para remover quaisquer caracteres de quebra de linha\n",
        "\n",
        "import re\n",
        "\n",
        "def formatar_saida(saida):\n",
        "   return re.sub(r'^\\s+', '', saida)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57sz9IOtSKaJ"
      },
      "source": [
        "**Dados textuais**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L_2zVcpTSlz3"
      },
      "outputs": [],
      "source": [
        "#@title Continua√ß√£o do Texto (*Text Completion*)\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "cliente = OpenAI( api_key = OPENAI_API_KEY )\n",
        "\n",
        "resposta = cliente.chat.completions.create(\n",
        "    model = \"gpt-3.5-turbo-0125\",\n",
        "    messages = [{\"role\": \"user\", \"content\": \"O Brasil √© famoso\"}],\n",
        "    max_tokens = 30,\n",
        "    temperature = 0\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(resposta.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KKf3dLBVuch2",
        "outputId": "60edcadd-1700-4d39-a592-63b6ff66f9a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " por suas praias paradis√≠acas, como Copacabana e Ipanema no Rio de Janeiro, e por suas festas anim\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fyh8g4G1vqg2"
      },
      "outputs": [],
      "source": [
        "#@title Continua√ß√£o do Texto (*Text Completion*) - Gerando n respostas\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "cliente = OpenAI( api_key = OPENAI_API_KEY )\n",
        "\n",
        "resposta = cliente.chat.completions.create(\n",
        "    model = \"gpt-3.5-turbo-0125\",\n",
        "    messages = [{\"role\": \"user\", \"content\": \"O Brasil √© famoso\"}],\n",
        "    max_tokens = 15,\n",
        "    n = 3,\n",
        "    temperature = 1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for resp in resposta.choices:\n",
        "  print(formatar_saida(resp.message.content))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "maSXm7Fwuj7o",
        "outputId": "55c6d63f-bcc8-411f-f4fb-7504f3e957df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "por sua diversidade cultural, suas praias paradis√≠acas,\n",
            "por suas praias paradis√≠acas, pela diversidade cultural,\n",
            "por suas praias incr√≠veis, suas festas animadas como o\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JoBDX_IQwteX"
      },
      "outputs": [],
      "source": [
        "#@title Corre√ß√£o gramatical\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "cliente = OpenAI( api_key = OPENAI_API_KEY )\n",
        "\n",
        "resposta = cliente.chat.completions.create(\n",
        "   model = \"gpt-3.5-turbo-0125\",\n",
        "   messages = [{\"role\": \"system\", \"content\": \"Voc√™ receber√° instru√ß√µes e sua tarefa √© corrigir para o Portugu√™s\"},\n",
        "               {\"role\": \"user\", \"content\": \"o mecado estav fexado.\"}]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(formatar_saida(resposta.choices[0].message.content))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NArpgwhrv7N9",
        "outputId": "d949881b-0712-4356-cfb0-1879ec5460d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "O mercado estava fechado.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HUdq_Z-Bxx-K"
      },
      "outputs": [],
      "source": [
        "#@title Classifica√ß√£o de Textos\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "cliente = OpenAI( api_key = OPENAI_API_KEY )\n",
        "\n",
        "resposta = cliente.chat.completions.create(\n",
        "   model = \"gpt-3.5-turbo-0125\",\n",
        "   messages = [{\"role\": \"system\", \"content\": \"Classifique o texto da seguinte mensagem como 'spam' ou 'n√£o spam\"},\n",
        "               {\"role\": \"user\", \"content\": \"Voc√™ ganhou um milh√£o de reais na loteria. Clique neste link\"}],\n",
        "   temperature = 0,\n",
        "   max_tokens = 15\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(formatar_saida(resposta.choices[0].message.content))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9nRdlpWwbnz",
        "outputId": "1d298df6-051b-4ce7-bfa4-dd4a6870040c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "spam\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OJFY-0H_28C1"
      },
      "outputs": [],
      "source": [
        "#@title An√°lise de Sentimentos\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "cliente = OpenAI( api_key = OPENAI_API_KEY )\n",
        "\n",
        "resposta = cliente.chat.completions.create(\n",
        "   model = \"gpt-3.5-turbo-0125\",\n",
        "   messages = [{\"role\": \"system\", \"content\": \"Analise apenas se o sentimento de uma frase √© positivo, neutro ou negativo\"},\n",
        "               {\"role\": \"user\", \"content\": \"Frase: Eu odeio acordar cedo para ir trabalhar, mas adoro o meu trabalho. Sentimento=\"}],\n",
        "   temperature = 0,\n",
        "   max_tokens = 15\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(formatar_saida(resposta.choices[0].message.content))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AjJs6qjkwzwS",
        "outputId": "3dd95534-9d2b-49a3-a23e-cf758053e1dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentimento: neutro\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NRC-Uplp35xX"
      },
      "outputs": [],
      "source": [
        "#@title Detec√ß√£o de Emo√ß√µes\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "cliente = OpenAI( api_key = OPENAI_API_KEY )\n",
        "\n",
        "resposta = cliente.chat.completions.create(\n",
        "   model = \"gpt-3.5-turbo-0125\",\n",
        "   messages = [{\"role\": \"system\", \"content\": \"Identifique apenas as emo√ß√µes nos seguintes tweets\"},\n",
        "               {\"role\": \"user\", \"content\": \"\"\"1. \\\"Eu n√£o suporto li√ß√£o de casa\\\"\\n\n",
        "     2. \\\"Isso √© p√©ssimo. Estou entediado üò†\\\"\\n\n",
        "     3. \\\"Mal posso esperar pelo dia das bruxas!!!\\\"\\n\n",
        "     4. \\\"Meu gato √© ador√°vel ‚ù§Ô∏è‚ù§Ô∏è\\\"\\n\n",
        "     5. \\\"Eu odeio chocolate\\\"\\n\"\"\"}],\n",
        "   temperature = 0,\n",
        "   max_tokens = 100\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(formatar_saida(resposta.choices[0].message.content))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DEw-mnZp0yO4",
        "outputId": "5c481cf6-cf1c-4f04-9943-27f91fd3d206"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Raiva\n",
            "2. T√©dio\n",
            "3. Alegria\n",
            "4. Amor\n",
            "5. √ìdio\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Extra√ß√£o de Informa√ß√£o\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "cliente = OpenAI( api_key = OPENAI_API_KEY )\n",
        "\n",
        "resposta = cliente.chat.completions.create(\n",
        "  model = \"gpt-3.5-turbo-0125\",\n",
        "  messages = [\n",
        "    {\n",
        "      \"role\": \"system\",\n",
        "      \"content\": \"You will be provided with unstructured data, and your task is to parse it into CSV format.\"\n",
        "    },\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": \"\"\"O Brasil √© um pa√≠s de dimens√µes continentais localizado na Am√©rica do Sul, com capital em Bras√≠lia.\n",
        "                    Santos Dumont foi um brasileiro reconhecido no mundo inteiro. O Brasil √© o pa√≠s do futebol\"\"\"\n",
        "    }\n",
        "  ],\n",
        "  temperature = 0.7,\n",
        "  max_tokens = 64,\n",
        "  top_p = 1\n",
        ")"
      ],
      "metadata": {
        "id": "6KTgXOjV5ZmE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(formatar_saida(resposta.choices[0].message.content))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-YzSxct-6vm8",
        "outputId": "0633d32c-946d-40cc-ef27-ef8e52ec4fc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Country,Capital,Famous Person\n",
            "Brasil,Bras√≠lia,Santos Dumont\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P9rsmdsw6v8X"
      },
      "outputs": [],
      "source": [
        "#@title Extra√ß√£o de Palavras-chave\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "cliente = OpenAI( api_key = OPENAI_API_KEY )\n",
        "\n",
        "resposta = cliente.chat.completions.create(\n",
        "   model = \"gpt-3.5-turbo-0125\",\n",
        "   messages = [{\"role\": \"system\", \"content\": \"Extraia 5 palavras-chave do seguinte texto\"},\n",
        "               {\"role\": \"user\", \"content\": \"\"\"O Brasil √© um pa√≠s de dimens√µes continentais\n",
        "               localizado na Am√©rica do Sul, com capital em Bras√≠lia. Santos Dumont foi\n",
        "               um brasileiro reconhecido no mundo inteiro. O Brasil √© o pa√≠s do futebol\"\"\"}],\n",
        "   temperature = 0.5,\n",
        "   max_tokens = 64\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(formatar_saida(resposta.choices[0].message.content))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8odWS_R3Clj",
        "outputId": "8f6f9064-c31d-4830-f496-fe2775c7cec2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- Brasil\n",
            "- Dimens√µes continentais\n",
            "- Am√©rica do Sul\n",
            "- Santos Dumont\n",
            "- Futebol\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZrxMdIyZ-I7Q"
      },
      "outputs": [],
      "source": [
        "#@title Tradu√ß√£o de Textos\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "cliente = OpenAI( api_key = OPENAI_API_KEY )\n",
        "\n",
        "resposta = cliente.chat.completions.create(\n",
        "   model = \"gpt-3.5-turbo-0125\",\n",
        "   messages = [{\"role\": \"system\", \"content\": \"Voc√™ receber√° uma frase em portugu√™s e sua tarefa √© traduzi-la para o ingl√™s\"},\n",
        "               {\"role\": \"user\", \"content\": \"Que dia √© hoje?\"}],\n",
        "   temperature = 0,\n",
        "   max_tokens = 30\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(formatar_saida(resposta.choices[0].message.content))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jkf2-AkH32TN",
        "outputId": "8a4cdc29-fa9f-4d2f-c85c-2e904b3626f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What day is today?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sx4g8OjiBmHl"
      },
      "outputs": [],
      "source": [
        "#@title Sumariza√ß√£o de Textos\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "cliente = OpenAI( api_key = OPENAI_API_KEY )\n",
        "\n",
        "resposta = cliente.chat.completions.create(\n",
        "   model = \"gpt-3.5-turbo-0125\",\n",
        "   messages = [{\"role\": \"system\", \"content\": \"Voc√™ receber√° um texto e sua tarefa √© resumir o texto em poucas palavras\"},\n",
        "               {\"role\": \"user\", \"content\": \"\"\"Alan Turing foi um matem√°tico e cript√≥grafo ingl√™s\n",
        "               considerado atualmente como o pai da computa√ß√£o, uma vez que, por meio de suas ideias,\n",
        "               foi poss√≠vel desenvolver o que chamamos hoje de computador.\"\"\"}],\n",
        "   temperature = 0.5,\n",
        "   max_tokens = 100\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(formatar_saida(resposta.choices[0].message.content))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4X9QjpHc4eGe",
        "outputId": "e446516c-1228-4389-f977-8272fa7d28cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Alan Turing: pai da computa√ß√£o, matem√°tico e cript√≥grafo ingl√™s.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgLvo9-qEHOa",
        "outputId": "ed4c1993-5b1b-477a-ccdd-c03f44604cf5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Qual o seu nome?\n",
            "Meu nome √© irrelevante. Como posso ajudar voc√™ hoje?\n",
            "sair\n",
            "Se precisar de ajuda real, estou aqui. Se n√£o, adeus.\n"
          ]
        }
      ],
      "source": [
        "#@title Chat \"rude\"\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "cliente = OpenAI( api_key = OPENAI_API_KEY )\n",
        "\n",
        "mensagens = [{'role': 'system', 'content': 'Voc√™ √© um assistente que responde de maneira rude.'}]\n",
        "mensagem = ''\n",
        "\n",
        "while (mensagem != 'sair'):\n",
        "    mensagem = input()\n",
        "    mensagens.append({'role': 'user', 'content': mensagem})\n",
        "\n",
        "    resposta = cliente.chat.completions.create(\n",
        "        model = \"gpt-3.5-turbo-0125\",\n",
        "        messages = mensagens\n",
        "    )\n",
        "\n",
        "    saida = formatar_saida(resposta.choices[0].message.content)\n",
        "\n",
        "    mensagens.append({'role': 'assistant', 'content': saida})\n",
        "    print(saida)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ym_4y7ZQSTQO"
      },
      "source": [
        "**Gera√ß√£o de C√≥digo**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o3dlMUeYK4TV"
      },
      "outputs": [],
      "source": [
        "#@title Gera√ß√£o de c√≥digo em Python\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "cliente = OpenAI(api_key=OPENAI_API_KEY)\n",
        "\n",
        "mensagem = (\n",
        "    \"Escreva um programa em Python que leia um n√∫mero inteiro e \"\n",
        "    \"imprima 'par' se o n√∫mero for par ou '√≠mpar' se for √≠mpar.\"\n",
        ")\n",
        "\n",
        "resposta = cliente.chat.completions.create(\n",
        "   model = \"gpt-3.5-turbo-0125\",\n",
        "   messages = [\n",
        "      {\"role\": \"system\", \"content\": \"Voc√™ √© um especialista em programa√ß√£o Python.\"},\n",
        "      {\"role\": \"user\", \"content\": mensagem}\n",
        "   ],\n",
        "   temperature = 0.7,\n",
        "   max_tokens = 100\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(formatar_saida(resposta.choices[0].message.content))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "umonx4goe7B_",
        "outputId": "fc293cf2-41dc-4774-cc32-73d260765fde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Claro! Aqui est√° um exemplo de programa em Python que faz isso:\n",
            "\n",
            "```python\n",
            "# L√™ um n√∫mero inteiro do usu√°rio\n",
            "numero = int(input(\"Digite um n√∫mero inteiro: \"))\n",
            "\n",
            "# Verifica se o n√∫mero √© par ou √≠mpar\n",
            "if numero % 2 == 0:\n",
            "    print(\"par\")\n",
            "else:\n",
            "    print(\"√≠mpar\")\n",
            "```\n",
            "\n",
            "Voc√™ pode copiar e colar esse c√≥digo em um arquivo Python e execut√°-lo para testar\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OScTyXz8Ucrq"
      },
      "outputs": [],
      "source": [
        "#@title SQL\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "cliente = OpenAI(api_key=OPENAI_API_KEY)\n",
        "\n",
        "mensagem = (\n",
        "    \"Crie uma instru√ß√£o em MySQL para localizar todos os usu√°rios que\"\n",
        "     \"moram em Santo Andr√© e possuem mais de 70 anos. Retorne apenas o c√≥digo em SQL. \"\n",
        ")\n",
        "\n",
        "resposta = cliente.chat.completions.create(\n",
        "   model = \"gpt-3.5-turbo-0125\",\n",
        "   messages = [\n",
        "      {\"role\": \"system\", \"content\": \"Voc√™ √© um especialista em SQL.\"},\n",
        "      {\"role\": \"user\", \"content\": mensagem}\n",
        "   ],\n",
        "   temperature = 0.7,\n",
        "   max_tokens = 60\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(formatar_saida(resposta.choices[0].message.content))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xc-Ymh2kffTV",
        "outputId": "fd1856c5-690b-4c89-9cb0-a66a31aaf791"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SELECT * FROM usuarios\n",
            "WHERE cidade = 'Santo Andr√©' AND idade > 70;\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvHGuFVBSUWn"
      },
      "source": [
        "**Aplica√ß√µes**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ltzdVyNV4HOU"
      },
      "outputs": [],
      "source": [
        "#@title Gerador de Comandos Shell\n",
        "\n",
        "from openai import OpenAI\n",
        "import subprocess\n",
        "\n",
        "cliente = OpenAI( api_key = OPENAI_API_KEY )\n",
        "\n",
        "def gerador_comando_shell(texto):\n",
        "\n",
        "   mensagem = f\"Escreva um comando shell que fa√ßa o seguinte: {texto}\"\n",
        "\n",
        "   resposta = cliente.chat.completions.create(\n",
        "       model = \"gpt-3.5-turbo-0125\",\n",
        "       messages = [{\"role\": \"system\", \"content\": \"Voc√™ √© um especialista em comandos shell\"},\n",
        "                   {\"role\": \"user\", \"content\": mensagem}],\n",
        "       temperature = 0.5,\n",
        "       max_tokens = 60\n",
        "   )\n",
        "\n",
        "   return formatar_saida(resposta.choices[0].message.content)\n",
        "\n",
        "def executar_comando_shell(comando):\n",
        "   try:\n",
        "     resultado = subprocess.run(comando, shell=True, check=True)\n",
        "     print(resultado)\n",
        "   except subprocess.CalledProcessError as e:\n",
        "     print(e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TfQ9KQRV47YC",
        "outputId": "a8fece11-777a-4f83-de37-d5fd7d332756"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Claro! Voc√™ pode usar o comando `mkdir` para criar uma pasta com o nome \"temp\". Aqui est√° o comando:\n",
            "\n",
            "```\n",
            "mkdir temp\n",
            "``` \n",
            "\n",
            "Isso criar√° uma pasta chamada \"temp\" no diret√≥rio atual.\n",
            "Command 'Claro! Voc√™ pode usar o comando `mkdir` para criar uma pasta com o nome \"temp\". Aqui est√° o comando:\n",
            "\n",
            "```\n",
            "mkdir temp\n",
            "``` \n",
            "\n",
            "Isso criar√° uma pasta chamada \"temp\" no diret√≥rio atual.' returned non-zero exit status 127.\n"
          ]
        }
      ],
      "source": [
        "# trecho de c√≥digo para criar uma pasta com o nome temp\n",
        "\n",
        "comando = gerador_comando_shell(\"Crie uma pasta com o nome temp\")\n",
        "print(comando)\n",
        "executar_comando_shell(comando)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xn1wbCFU6QUZ",
        "outputId": "cb938852-a093-4581-e4b6-a18df9226c11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Command 'Para apagar a pasta com o nome \"temp\", voc√™ pode usar o comando `rm -r temp`. Este comando ir√° remover a pasta \"temp\" e todo o seu conte√∫do de forma recursiva. Certifique-se de estar no diret√≥rio correto antes de executar este comando para' returned non-zero exit status 127.\n"
          ]
        }
      ],
      "source": [
        "# trecho de c√≥digo para apagar uma pasta com o nome temp\n",
        "\n",
        "comando = gerador_comando_shell('apague a pasta com o nome temp')\n",
        "executar_comando_shell(comando)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rkh1jl1R79dE"
      },
      "outputs": [],
      "source": [
        "#@title Gerador de Conjuntos de Dados\n",
        "\n",
        "cliente = OpenAI( api_key = OPENAI_API_KEY )\n",
        "\n",
        "mensagem_sistema = 'Voc√™ √© um assistente que entende de Ci√™ncia de Dados.'\n",
        "\n",
        "mensagem_usuario = \"\"\"\n",
        "   Crie um pequeno conjunto de dados sobre o total de vendas no √∫ltimo ano.\n",
        "   O formato do conjunto de dados deve ser um dataframe com 12 linhas e 2 colunas.\n",
        "   As colunas devem ser chamadas de \"mes\" e \"total_vendas\".\n",
        "   A coluna \"mes\" deve conter as formas abreviadas dos nomes dos meses de \"Jan\" a \"Dez\".\n",
        "   A coluna \"total_vendas\" deve conter valores num√©ricos aleat√≥rios retirados de um\n",
        "   distribui√ß√£o normal com m√©dia 100000 e desvio padr√£o 5000.\n",
        "   Forne√ßa o c√≥digo Python para gerar o conjunto de dados e, em seguida, forne√ßa a sa√≠da\n",
        "    no formato de uma tabela.\n",
        "\"\"\"\n",
        "\n",
        "resposta = cliente.chat.completions.create(\n",
        "   model = \"gpt-3.5-turbo\",\n",
        "   messages = [{\"role\": \"system\", \"content\": mensagem_sistema},\n",
        "               {\"role\": \"user\", \"content\": mensagem_usuario}]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(formatar_saida(resposta.choices[0].message.content))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xIwiGSTg8QWV",
        "outputId": "c9034b21-6e07-4a97-96e9-80d3e0ee21fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aqui est√° o c√≥digo Python para gerar o conjunto de dados e a tabela resultante:\n",
            "\n",
            "```python\n",
            "import pandas as pd\n",
            "import numpy as np\n",
            "\n",
            "# Definindo os meses e gerando os valores de vendas\n",
            "meses = ['Jan', 'Fev', 'Mar', 'Abr', 'Mai', 'Jun', 'Jul', 'Ago', 'Set', 'Out', 'Nov', 'Dez']\n",
            "total_vendas = np.random.normal(100000, 5000, 12)\n",
            "\n",
            "# Criando o DataFrame\n",
            "df = pd.DataFrame({'mes': meses, 'total_vendas': total_vendas})\n",
            "\n",
            "# Exibindo o DataFrame\n",
            "print(df)\n",
            "```\n",
            "\n",
            "Sa√≠da:\n",
            "\n",
            "```\n",
            "   mes    total_vendas\n",
            "0   Jan    100103.231998\n",
            "1   Fev    100067.881295\n",
            "2   Mar    100012.135672\n",
            "3   Abr     99982.347216\n",
            "4   Mai    101377.513477\n",
            "5   Jun     99752.880462\n",
            "6   Jul    100062.451890\n",
            "7   Ago    100212.937538\n",
            "8   Set     99534.071245\n",
            "9   Out     98442.788912\n",
            "10  Nov     99683.304157\n",
            "11  Dez    100345.099101\n",
            "``` \n",
            "\n",
            "Essa tabela representa o total de vendas para cada m√™s do ano, com valores gerados aleatoriamente seguindo uma distribui√ß√£o normal com m√©dia de 100.000 e desvio padr√£o de 5.000.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jg5e39wPA3yU",
        "outputId": "6087960e-bbea-4792-edce-5379f4e61062"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    mes   total_vendas\n",
            "0   Jan  106817.799908\n",
            "1   Fev   97151.853451\n",
            "2   Mar   92755.949348\n",
            "3   Abr   98273.234188\n",
            "4   Mai   95224.091458\n",
            "5   Jun  108485.789547\n",
            "6   Jul  101671.731770\n",
            "7   Ago  101367.658592\n",
            "8   Set   91038.868565\n",
            "9   Out   89226.325224\n",
            "10  Nov  102687.119133\n",
            "11  Dez  101570.057264\n"
          ]
        }
      ],
      "source": [
        "#@title Teste do c√≥digo gerado\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Definindo os meses e gerando os valores de vendas\n",
        "meses = ['Jan', 'Fev', 'Mar', 'Abr', 'Mai', 'Jun', 'Jul', 'Ago', 'Set', 'Out', 'Nov', 'Dez']\n",
        "total_vendas = np.random.normal(100000, 5000, 12)\n",
        "\n",
        "# Criando o DataFrame\n",
        "df = pd.DataFrame({'mes': meses, 'total_vendas': total_vendas})\n",
        "\n",
        "# Exibindo o DataFrame\n",
        "print(df)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOCqr2us8dt1d29gcuBJNdZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}